digraph {
	graph [size="48.449999999999996,48.449999999999996"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140521211676128 [label="
 (1, 1)" fillcolor=darkolivegreen1]
	140521200474848 [label=SigmoidBackward0]
	140521200475616 -> 140521200474848
	140521200475616 [label=AddmmBackward0]
	140521200475424 -> 140521200475616
	140521200652336 [label="fc2.bias
 (1)" fillcolor=lightblue]
	140521200652336 -> 140521200475424
	140521200475424 [label=AccumulateGrad]
	140521200475664 -> 140521200475616
	140521200475664 [label=ReluBackward0]
	140521200475472 -> 140521200475664
	140521200475472 [label=AddmmBackward0]
	140521200475856 -> 140521200475472
	140521215138512 [label="fc.bias
 (128)" fillcolor=lightblue]
	140521215138512 -> 140521200475856
	140521200475856 [label=AccumulateGrad]
	140521200475808 -> 140521200475472
	140521200475808 [label=ViewBackward0]
	140521200475952 -> 140521200475808
	140521200475952 [label=ReluBackward0]
	140521200476144 -> 140521200475952
	140521200476144 [label=AddBackward0]
	140521200476240 -> 140521200476144
	140521200476240 [label=NativeBatchNormBackward0]
	140521200476384 -> 140521200476240
	140521200476384 [label=ConvolutionBackward0]
	140521200476576 -> 140521200476384
	140521200476576 [label=ReluBackward0]
	140521200476768 -> 140521200476576
	140521200476768 [label=NativeBatchNormBackward0]
	140521200476864 -> 140521200476768
	140521200476864 [label=ConvolutionBackward0]
	140521200477056 -> 140521200476864
	140521200477056 [label=ReluBackward0]
	140521200477248 -> 140521200477056
	140521200477248 [label=AddBackward0]
	140521200477344 -> 140521200477248
	140521200477344 [label=NativeBatchNormBackward0]
	140521200477488 -> 140521200477344
	140521200477488 [label=ConvolutionBackward0]
	140521200477680 -> 140521200477488
	140521200477680 [label=ReluBackward0]
	140521200477872 -> 140521200477680
	140521200477872 [label=NativeBatchNormBackward0]
	140521200477968 -> 140521200477872
	140521200477968 [label=ConvolutionBackward0]
	140521200478160 -> 140521200477968
	140521200478160 [label=ReluBackward0]
	140521200478352 -> 140521200478160
	140521200478352 [label=AddBackward0]
	140521200478448 -> 140521200478352
	140521200478448 [label=NativeBatchNormBackward0]
	140521200478592 -> 140521200478448
	140521200478592 [label=ConvolutionBackward0]
	140521200478784 -> 140521200478592
	140521200478784 [label=ReluBackward0]
	140521200478976 -> 140521200478784
	140521200478976 [label=NativeBatchNormBackward0]
	140521200479072 -> 140521200478976
	140521200479072 [label=ConvolutionBackward0]
	140521200479264 -> 140521200479072
	140521200479264 [label=ReluBackward0]
	140521200479456 -> 140521200479264
	140521200479456 [label=AddBackward0]
	140521200479552 -> 140521200479456
	140521200479552 [label=NativeBatchNormBackward0]
	140521200479696 -> 140521200479552
	140521200479696 [label=ConvolutionBackward0]
	140521200479888 -> 140521200479696
	140521200479888 [label=ReluBackward0]
	140521200480080 -> 140521200479888
	140521200480080 [label=NativeBatchNormBackward0]
	140521200480176 -> 140521200480080
	140521200480176 [label=ConvolutionBackward0]
	140521200480368 -> 140521200480176
	140521200480368 [label=MaxPool2DWithIndicesBackward0]
	140521200480560 -> 140521200480368
	140521200480560 [label=ReluBackward0]
	140521200480656 -> 140521200480560
	140521200480656 [label=NativeBatchNormBackward0]
	140521200480752 -> 140521200480656
	140521200480752 [label=ConvolutionBackward0]
	140521200480944 -> 140521200480752
	140521211045632 [label="conv1.weight
 (64, 65, 7, 7)" fillcolor=lightblue]
	140521211045632 -> 140521200480944
	140521200480944 [label=AccumulateGrad]
	140521200480896 -> 140521200480752
	140521200493376 [label="conv1.bias
 (64)" fillcolor=lightblue]
	140521200493376 -> 140521200480896
	140521200480896 [label=AccumulateGrad]
	140521200480704 -> 140521200480656
	140521221855312 [label="bn1.weight
 (64)" fillcolor=lightblue]
	140521221855312 -> 140521200480704
	140521200480704 [label=AccumulateGrad]
	140521200480464 -> 140521200480656
	140521215549152 [label="bn1.bias
 (64)" fillcolor=lightblue]
	140521215549152 -> 140521200480464
	140521200480464 [label=AccumulateGrad]
	140521200480320 -> 140521200480176
	140521215631792 [label="residual_block1.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	140521215631792 -> 140521200480320
	140521200480320 [label=AccumulateGrad]
	140521200480272 -> 140521200480176
	140521223268896 [label="residual_block1.conv1.bias
 (128)" fillcolor=lightblue]
	140521223268896 -> 140521200480272
	140521200480272 [label=AccumulateGrad]
	140521200480128 -> 140521200480080
	140521223262416 [label="residual_block1.bn1.weight
 (128)" fillcolor=lightblue]
	140521223262416 -> 140521200480128
	140521200480128 [label=AccumulateGrad]
	140521200479984 -> 140521200480080
	140521200493616 [label="residual_block1.bn1.bias
 (128)" fillcolor=lightblue]
	140521200493616 -> 140521200479984
	140521200479984 [label=AccumulateGrad]
	140521200479840 -> 140521200479696
	140521200494096 [label="residual_block1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	140521200494096 -> 140521200479840
	140521200479840 [label=AccumulateGrad]
	140521200479792 -> 140521200479696
	140521200494176 [label="residual_block1.conv2.bias
 (128)" fillcolor=lightblue]
	140521200494176 -> 140521200479792
	140521200479792 [label=AccumulateGrad]
	140521200479648 -> 140521200479552
	140521200494256 [label="residual_block1.bn2.weight
 (128)" fillcolor=lightblue]
	140521200494256 -> 140521200479648
	140521200479648 [label=AccumulateGrad]
	140521200479600 -> 140521200479552
	140521200494336 [label="residual_block1.bn2.bias
 (128)" fillcolor=lightblue]
	140521200494336 -> 140521200479600
	140521200479600 [label=AccumulateGrad]
	140521200479504 -> 140521200479456
	140521200479504 [label=NativeBatchNormBackward0]
	140521200480032 -> 140521200479504
	140521200480032 [label=ConvolutionBackward0]
	140521200480368 -> 140521200480032
	140521200480608 -> 140521200480032
	140521200494816 [label="residual_block1.downsample.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	140521200494816 -> 140521200480608
	140521200480608 [label=AccumulateGrad]
	140521200480512 -> 140521200480032
	140521200494896 [label="residual_block1.downsample.0.bias
 (128)" fillcolor=lightblue]
	140521200494896 -> 140521200480512
	140521200480512 [label=AccumulateGrad]
	140521200479936 -> 140521200479504
	140521200494976 [label="residual_block1.downsample.1.weight
 (128)" fillcolor=lightblue]
	140521200494976 -> 140521200479936
	140521200479936 [label=AccumulateGrad]
	140521200479744 -> 140521200479504
	140521200495056 [label="residual_block1.downsample.1.bias
 (128)" fillcolor=lightblue]
	140521200495056 -> 140521200479744
	140521200479744 [label=AccumulateGrad]
	140521200479216 -> 140521200479072
	140521200495376 [label="residual_block2.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	140521200495376 -> 140521200479216
	140521200479216 [label=AccumulateGrad]
	140521200479168 -> 140521200479072
	140521200495456 [label="residual_block2.conv1.bias
 (256)" fillcolor=lightblue]
	140521200495456 -> 140521200479168
	140521200479168 [label=AccumulateGrad]
	140521200479024 -> 140521200478976
	140521200495536 [label="residual_block2.bn1.weight
 (256)" fillcolor=lightblue]
	140521200495536 -> 140521200479024
	140521200479024 [label=AccumulateGrad]
	140521200478880 -> 140521200478976
	140521200495616 [label="residual_block2.bn1.bias
 (256)" fillcolor=lightblue]
	140521200495616 -> 140521200478880
	140521200478880 [label=AccumulateGrad]
	140521200478736 -> 140521200478592
	140521200496096 [label="residual_block2.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	140521200496096 -> 140521200478736
	140521200478736 [label=AccumulateGrad]
	140521200478688 -> 140521200478592
	140521200496176 [label="residual_block2.conv2.bias
 (256)" fillcolor=lightblue]
	140521200496176 -> 140521200478688
	140521200478688 [label=AccumulateGrad]
	140521200478544 -> 140521200478448
	140521200496256 [label="residual_block2.bn2.weight
 (256)" fillcolor=lightblue]
	140521200496256 -> 140521200478544
	140521200478544 [label=AccumulateGrad]
	140521200478496 -> 140521200478448
	140521200496336 [label="residual_block2.bn2.bias
 (256)" fillcolor=lightblue]
	140521200496336 -> 140521200478496
	140521200478496 [label=AccumulateGrad]
	140521200478400 -> 140521200478352
	140521200478400 [label=NativeBatchNormBackward0]
	140521200478928 -> 140521200478400
	140521200478928 [label=ConvolutionBackward0]
	140521200479264 -> 140521200478928
	140521200479360 -> 140521200478928
	140521200496736 [label="residual_block2.downsample.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	140521200496736 -> 140521200479360
	140521200479360 [label=AccumulateGrad]
	140521200479408 -> 140521200478928
	140521200496816 [label="residual_block2.downsample.0.bias
 (256)" fillcolor=lightblue]
	140521200496816 -> 140521200479408
	140521200479408 [label=AccumulateGrad]
	140521200478832 -> 140521200478400
	140521200496896 [label="residual_block2.downsample.1.weight
 (256)" fillcolor=lightblue]
	140521200496896 -> 140521200478832
	140521200478832 [label=AccumulateGrad]
	140521200478640 -> 140521200478400
	140521200496976 [label="residual_block2.downsample.1.bias
 (256)" fillcolor=lightblue]
	140521200496976 -> 140521200478640
	140521200478640 [label=AccumulateGrad]
	140521200478112 -> 140521200477968
	140521200497456 [label="residual_block3.conv1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	140521200497456 -> 140521200478112
	140521200478112 [label=AccumulateGrad]
	140521200478064 -> 140521200477968
	140521200497536 [label="residual_block3.conv1.bias
 (512)" fillcolor=lightblue]
	140521200497536 -> 140521200478064
	140521200478064 [label=AccumulateGrad]
	140521200477920 -> 140521200477872
	140521200497616 [label="residual_block3.bn1.weight
 (512)" fillcolor=lightblue]
	140521200497616 -> 140521200477920
	140521200477920 [label=AccumulateGrad]
	140521200477776 -> 140521200477872
	140521200497696 [label="residual_block3.bn1.bias
 (512)" fillcolor=lightblue]
	140521200497696 -> 140521200477776
	140521200477776 [label=AccumulateGrad]
	140521200477632 -> 140521200477488
	140521200498176 [label="residual_block3.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	140521200498176 -> 140521200477632
	140521200477632 [label=AccumulateGrad]
	140521200477584 -> 140521200477488
	140521200498256 [label="residual_block3.conv2.bias
 (512)" fillcolor=lightblue]
	140521200498256 -> 140521200477584
	140521200477584 [label=AccumulateGrad]
	140521200477440 -> 140521200477344
	140521200498336 [label="residual_block3.bn2.weight
 (512)" fillcolor=lightblue]
	140521200498336 -> 140521200477440
	140521200477440 [label=AccumulateGrad]
	140521200477392 -> 140521200477344
	140521200498416 [label="residual_block3.bn2.bias
 (512)" fillcolor=lightblue]
	140521200498416 -> 140521200477392
	140521200477392 [label=AccumulateGrad]
	140521200477296 -> 140521200477248
	140521200477296 [label=NativeBatchNormBackward0]
	140521200477824 -> 140521200477296
	140521200477824 [label=ConvolutionBackward0]
	140521200478160 -> 140521200477824
	140521200478256 -> 140521200477824
	140521200498896 [label="residual_block3.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	140521200498896 -> 140521200478256
	140521200478256 [label=AccumulateGrad]
	140521200478304 -> 140521200477824
	140521200498976 [label="residual_block3.downsample.0.bias
 (512)" fillcolor=lightblue]
	140521200498976 -> 140521200478304
	140521200478304 [label=AccumulateGrad]
	140521200477728 -> 140521200477296
	140521200499056 [label="residual_block3.downsample.1.weight
 (512)" fillcolor=lightblue]
	140521200499056 -> 140521200477728
	140521200477728 [label=AccumulateGrad]
	140521200477536 -> 140521200477296
	140521200499136 [label="residual_block3.downsample.1.bias
 (512)" fillcolor=lightblue]
	140521200499136 -> 140521200477536
	140521200477536 [label=AccumulateGrad]
	140521200477008 -> 140521200476864
	140521200499616 [label="residual_block4.conv1.weight
 (1024, 512, 3, 3)" fillcolor=lightblue]
	140521200499616 -> 140521200477008
	140521200477008 [label=AccumulateGrad]
	140521200476960 -> 140521200476864
	140521200499696 [label="residual_block4.conv1.bias
 (1024)" fillcolor=lightblue]
	140521200499696 -> 140521200476960
	140521200476960 [label=AccumulateGrad]
	140521200476816 -> 140521200476768
	140521200499776 [label="residual_block4.bn1.weight
 (1024)" fillcolor=lightblue]
	140521200499776 -> 140521200476816
	140521200476816 [label=AccumulateGrad]
	140521200476672 -> 140521200476768
	140521200499856 [label="residual_block4.bn1.bias
 (1024)" fillcolor=lightblue]
	140521200499856 -> 140521200476672
	140521200476672 [label=AccumulateGrad]
	140521200476528 -> 140521200476384
	140521200500336 [label="residual_block4.conv2.weight
 (1024, 1024, 3, 3)" fillcolor=lightblue]
	140521200500336 -> 140521200476528
	140521200476528 [label=AccumulateGrad]
	140521200476480 -> 140521200476384
	140521200500416 [label="residual_block4.conv2.bias
 (1024)" fillcolor=lightblue]
	140521200500416 -> 140521200476480
	140521200476480 [label=AccumulateGrad]
	140521200476336 -> 140521200476240
	140521200500496 [label="residual_block4.bn2.weight
 (1024)" fillcolor=lightblue]
	140521200500496 -> 140521200476336
	140521200476336 [label=AccumulateGrad]
	140521200476288 -> 140521200476240
	140521200500576 [label="residual_block4.bn2.bias
 (1024)" fillcolor=lightblue]
	140521200500576 -> 140521200476288
	140521200476288 [label=AccumulateGrad]
	140521200476192 -> 140521200476144
	140521200476192 [label=NativeBatchNormBackward0]
	140521200476720 -> 140521200476192
	140521200476720 [label=ConvolutionBackward0]
	140521200477056 -> 140521200476720
	140521200477152 -> 140521200476720
	140521200648576 [label="residual_block4.downsample.0.weight
 (1024, 512, 1, 1)" fillcolor=lightblue]
	140521200648576 -> 140521200477152
	140521200477152 [label=AccumulateGrad]
	140521200477200 -> 140521200476720
	140521200648656 [label="residual_block4.downsample.0.bias
 (1024)" fillcolor=lightblue]
	140521200648656 -> 140521200477200
	140521200477200 [label=AccumulateGrad]
	140521200476624 -> 140521200476192
	140521200648736 [label="residual_block4.downsample.1.weight
 (1024)" fillcolor=lightblue]
	140521200648736 -> 140521200476624
	140521200476624 [label=AccumulateGrad]
	140521200476432 -> 140521200476192
	140521200648816 [label="residual_block4.downsample.1.bias
 (1024)" fillcolor=lightblue]
	140521200648816 -> 140521200476432
	140521200476432 [label=AccumulateGrad]
	140521200475760 -> 140521200475472
	140521200475760 [label=TBackward0]
	140521200476048 -> 140521200475760
	140521221850272 [label="fc.weight
 (128, 65536)" fillcolor=lightblue]
	140521221850272 -> 140521200476048
	140521200476048 [label=AccumulateGrad]
	140521200475520 -> 140521200475616
	140521200475520 [label=TBackward0]
	140521200476096 -> 140521200475520
	140521200652416 [label="fc2.weight
 (1, 128)" fillcolor=lightblue]
	140521200652416 -> 140521200476096
	140521200476096 [label=AccumulateGrad]
	140521200474848 -> 140521211676128
}
